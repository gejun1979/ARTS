当我们使用机器学习做决定的时候，我们怎么知道做这个决定的理由是什么？比如，阿尔法go击败了最强的人类选手，那么他每下一步棋的理由是什么？现在的机器学习越来越关注机器做的决定是否可解释。
